{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is basically simple attention mechanism with trainable weights\n",
    "## so intead of just taking dot product between the embedding vectors \n",
    "## of words we will have keys, query and value vectors which are obtained \n",
    "## by transforming the embedding by trainable weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = 3 # input dimension of the embeddings \n",
    "d_out = 2 # output dimension for k,q,v,vectors [generally they are same]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "\n",
    "\n",
    "## here we are not training hence keeping requires_grad=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n"
     ]
    }
   ],
   "source": [
    "print(W_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: torch.Size([6, 2])\n",
      "Queries: torch.Size([6, 2])\n",
      "Values: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "queries = inputs @ W_query\n",
    "values = inputs @ W_value\n",
    "\n",
    "print(f\"Keys: {keys.shape}\")\n",
    "print(f\"Queries: {queries.shape}\")\n",
    "print(f\"Values: {values.shape}\")\n",
    "\n",
    "## Now we will compute the attention weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores: torch.Size([6, 6])\n",
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = queries @ keys.T\n",
    "\n",
    "print(f\"Attention Scores: {attention_scores.shape}\")\n",
    "\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores: torch.Size([6, 6])\n",
      "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
      "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
      "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
      "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
      "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
      "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
     ]
    }
   ],
   "source": [
    "## Now these attention scores are first scaled by 1/sqrt(d_out) [todo: why?]\n",
    "\n",
    "attention_scores = attention_scores / torch.sqrt(torch.tensor(d_out))\n",
    "\n",
    "attention_scores = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "print(f\"Attention Scores: {attention_scores.shape}\")\n",
    "\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function is sensitive to the magnitudes of its inputs. When the inputs are large, the differences between the exponential values of each input become much more pronounced. This causes the softmax output to become \"peaky,\" where the highest value receives almost all the probability mass, and the rest receive very little.\n",
    "\n",
    "In attention mechanisms, particularly in transformers, if the dot products between query and key vectors become too large , the attention scores can become very large. This results in a very sharp softmax distribution, making the model overly confident in one particular \"key.\" Such sharp distributions can make learning unstable,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " But still why is it divided by sqrt(d_out)?\n",
    "\n",
    " It turns out that the higher the dimension of the vector, the more is it's variance.\n",
    "\n",
    " And dividing by sqrt(d_out) makes the variance of the scores close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention shape: torch.Size([6, 2])\n",
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]])\n"
     ]
    }
   ],
   "source": [
    "## now we have the attention scores let's calculate the context vectors \n",
    "\n",
    "## so calculating context vectors is bascially in attention scores we have attention score \n",
    "## that each query has to give to all others and basically now we will scale the values of each query \n",
    "## wrt to their attention score and then sum it up so this way we have with us the enriched context vectors \n",
    "## for each query\n",
    "\n",
    "context_vectors = attention_scores @ values\n",
    "\n",
    "print(f\"Attention shape: {context_vectors.shape}\")\n",
    "\n",
    "print(context_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v1(torch.nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "\n",
    "    def forward(self,x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attention_scores = queries @ keys.T\n",
    "        attention_scores = torch.softmax(attention_scores / keys.shape[-1]**0.5,dim=-1)\n",
    "        context_vectors = attention_scores @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "self_attention = SelfAttention_v1(d_in=3,d_out=2)\n",
    "\n",
    "print(self_attention(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
