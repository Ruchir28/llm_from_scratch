{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (output_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_skip_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.transformer as transformer\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "model = transformer.GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probablity = torch.softmax(logits, dim=-1)\n",
    "\n",
    "print(probablity.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probablity, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target token probabilities: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n"
     ]
    }
   ],
   "source": [
    "## So as model isn't trained, we can see the output is random\n",
    "# let's check what is the targer probaily i.e. probability of the target token\n",
    "\n",
    "target_prob = probablity[0, torch.arange(token_ids.shape[1]), targets[0]]\n",
    "print(f\"Target token probabilities: {target_prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# logits is of shape (batch_size * context_length, vocab_size)\n",
    "# targets is of shape (batch_size * context_length)\n",
    "# and target contains the index of the target token in the vocabulary\n",
    "# so cross entropy loss will first get the logits from the logits_flat for the targets_flat\n",
    "# indicers , softmax the logits and then take the values of the targets_flat indicers\n",
    "# and then compute the mean of the loss and finally negate it\n",
    "\n",
    "## we negate the log avg probabilty as log in 0 to 1 is lowest when x=0 and higert when x=1(y=0)\n",
    "# so we negate it to make it lowest when x=1 and highest when x=0\n",
    "# and hence we will have a loss function \n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it's going to send the value of my picture 'way up; but I don't think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing's lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn's \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\n",
      "\n",
      "Well!--even through th\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "print(text_data[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = tokenizer.encode(text_data)\n",
    "print(f\"Total tokens: {len(token_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1] \n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "\n",
    "def create_dataloader_v1(text,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            num_workers=num_workers)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ration = 0.9\n",
    "split_idx = int(train_ration * len(text_data))\n",
    "\n",
    "train_text = text_data[:split_idx]\n",
    "val_text = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Val loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(f\"Val loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch,target_batch = input_batch.to(device),target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calculate_loss_batch(input_batch,target_batch,model,device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.9876, Val loss: 10.9811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transformer import generate_text\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text(\n",
    "            model=model, input=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,\n",
    "                        eval_iter,start_context,tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calculate_loss_batch(input_batch=input_batch,\n",
    "                                        target_batch=target_batch,\n",
    "                                        model=model,\n",
    "                                        device=device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        generate_and_print_sample(model,tokenizer,device,start_context)\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen         \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0, Train Loss: 9.7810, Val Loss: 9.9328\n",
      "Epoch 1, Step 5, Train Loss: 8.0718, Val Loss: 8.3405\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Epoch 2, Step 10, Train Loss: 6.7521, Val Loss: 7.0443\n",
      "Epoch 2, Step 15, Train Loss: 6.0936, Val Loss: 6.5975\n",
      "Every effort moves you, the,, the,, the,,,,.                                     \n",
      "Epoch 3, Step 20, Train Loss: 6.1969, Val Loss: 6.8208\n",
      "Epoch 3, Step 25, Train Loss: 5.2368, Val Loss: 6.3722\n",
      "Every effort moves you.               \"I was the picture.      \"I was the the picture. \"I the honour, and I had\"I was.  \n",
      "Epoch 4, Step 30, Train Loss: 4.8566, Val Loss: 6.2772\n",
      "Epoch 4, Step 35, Train Loss: 4.2070, Val Loss: 6.2623\n",
      "Every effort moves you, and I had been the picture of the picture.                                       \n",
      "Epoch 5, Step 40, Train Loss: 4.0783, Val Loss: 6.2426\n",
      "Every effort moves you know it was not to the picture--I to the                                       \n",
      "Epoch 6, Step 45, Train Loss: 3.2250, Val Loss: 6.1317\n",
      "Epoch 6, Step 50, Train Loss: 2.3929, Val Loss: 6.1506\n",
      "Every effort moves you know,\" was not that I felt as it--I had a good-rooms, and he was, and in fact, and I had been the moment--as Jack himself, as his own painting, of Jack's \"strong. Gisburn\n",
      "Epoch 7, Step 55, Train Loss: 2.0737, Val Loss: 6.2370\n",
      "Epoch 7, Step 60, Train Loss: 1.6791, Val Loss: 6.2392\n",
      "Every effort moves you?\" \" on a little Mrs.  \"--as such--had not till his--and that one of Jack's degree to the donkey. \"I-c. \"I looked up his pictures--because he had been his\n",
      "Epoch 8, Step 65, Train Loss: 1.2811, Val Loss: 6.2866\n",
      "Epoch 8, Step 70, Train Loss: 0.9875, Val Loss: 6.3327\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back his glory, and as once one had I turned, and down the room, when I\n",
      "Epoch 9, Step 75, Train Loss: 0.6456, Val Loss: 6.3788\n",
      "Epoch 9, Step 80, Train Loss: 0.4121, Val Loss: 6.4376\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Epoch 10, Step 85, Train Loss: 0.3317, Val Loss: 6.5143\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Training completed in 2.75 minutes.\n"
     ]
    }
   ],
   "source": [
    "from utils.transformer import GPTModel\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,train_loader=train_loader,val_loader=val_loader,optimizer=optimizer,device=device,\n",
    "    num_epochs=num_epochs,eval_freq=5,eval_iter=5,start_context=\"Every effort moves you\",tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
