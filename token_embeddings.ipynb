{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why can't we just feed the tokenized text into the model?\n",
    "### Why have seperate embeddings ?\n",
    "\n",
    "Because random text doesn't denote any semantic meaning.\n",
    "for ex: cat and kitten are similar but can have very different tokens assigned to them.\n",
    "\n",
    "And why it's important?\n",
    "\n",
    "Because even in case on cnn we see that they understand the relation between different objects they detect and their spatial relation.\n",
    "\n",
    "so similarly here, the meaning of the text their relation to each other and it's position in the sentence is important.\n",
    "\n",
    "so we use embeddings to represent the meaning of the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "vocab_size = 50247\n",
    "\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 256])\n"
     ]
    }
   ],
   "source": [
    "embeddings = token_embedding_layer(torch.tensor([1, 2, 3, 4, 5]))\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0,len(tokens_ids) - max_length,stride):\n",
    "            input_chunk = tokens_ids[i:i+max_length]\n",
    "            target_chunk = tokens_ids[i+1:i+max_length+1]\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "            ## each input output pairs is a tensor of shape (max_lengthx)\n",
    "            ## and it contains max_length prediction task\n",
    "            ## i.e. if max_length = 4\n",
    "            ## then input is [model, predicts, next, token]\n",
    "            ## and target is [predicts,next,  token, end_of_text]\n",
    "\n",
    "            ## so pairs like : model -> predicts\n",
    "            ##           model predicts -> next\n",
    "            ##           model predicts next -> token\n",
    "            ##           model predicts next token -> end_of_text\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        self.enc_text = tokenizer.encode(txt)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    # initalize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # initialize the dataset\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "\n",
    "    # create the dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader_v1(raw_text,batch_size=4,max_length=4,stride=4,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[27075,    11,   290,  4920],\n",
      "        [ 2241,   287,   257,  4489],\n",
      "        [   64,   319,   262, 34686],\n",
      "        [41976,    13,   357, 10915]]), tensor([[   11,   290,  4920,  2241],\n",
      "        [  287,   257,  4489,    64],\n",
      "        [  319,   262, 34686, 41976],\n",
      "        [   13,   357, 10915,   314]])]\n",
      "first batch shape x:torch.Size([4, 4]), y:torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "\n",
    "x,y = first_batch\n",
    "\n",
    "print(f'first batch shape x:{x.shape}, y:{y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input batch shape: torch.Size([4, 4]) \n",
      "input embedding shape : torch.Size([4, 4, 256])\n",
      "\n",
      "torch.Size([4, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "first_batch_embeddings = token_embedding_layer(x)\n",
    "\n",
    "\n",
    "print(f'''input batch shape: {x.shape} \n",
    "input embedding shape : {first_batch_embeddings.shape}\n",
    "''')\n",
    "print(first_batch_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embeddings\n",
    "\n",
    "# ![](image.png)\n",
    "\n",
    "Important because the if the tokens remains same at different poistion their embeddings is still different due to position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of positional embeddings depend on the context length because we have only one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 4\n",
    "embedding_dim = 256\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length,embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position indices shape: torch.Size([4])\n",
      "Positional embeddings shape: torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "positions = torch.arange(context_length)\n",
    "print(f\"Position indices shape: {positions.shape}\")\n",
    "\n",
    "pos_embeddings = pos_embedding_layer(positions)\n",
    "print(f\"Positional embeddings shape: {pos_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch embeddings : torch.Size([4, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "first_batch_input_embeddings = first_batch_embeddings + pos_embeddings\n",
    "\n",
    "print(f'first batch embeddings : {first_batch_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
